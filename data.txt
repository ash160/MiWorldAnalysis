............................************************............................
{'namespace': 'common_models.async_viewset', 'created_by': 'sys', 'source_code': '#import uuid\n\n#import datetime\n\n#from db_manager_viewset import cassandra_manager_obj, cache_manager_obj\n#from cache_manager import cache_manager_obj\n#from cassandra_manager import cassandra_manager\n#from post_gras_manager import post_gras_manager\n\n\n\nclass ViewSetMaster(GenClass):\n    permission_class = ParmissionChacker\n    lookup_field =\'user\'\n    loop_index = None\n    pk = \'pk\'\n    serializer_class = None #Serializer\n    require_user_mapping = False\n    user_fild = None\n    model_name = ""\n    tmp_cache=None\n    db_manager_class = None #DB_client\n    db_manager_client = None\n    allow_function =[\'*\']\n    permission_list = [\'read\',\'write\',\'edit\',\'delete\']\n    function_dict= {\n            \'list\':[\'list\',\'get\'],\n            \'create\':[\'create\',\'post\'],\n            \'retrive\':[\'retrive\',\'get\'],\n            \'update\':[\'update\',\'put\'],\n            \'destroy\':[\'destroy\',\'post\'],\n            \'partial_update\':[\'partial_update\',\'put\']\n            }\n\n\n    def id_generetor(user):\n        return user+str(datetime.datetime.timestamp())\n\n    def __init__(self,thread_manager_obj,loop_index):\n        self.permission_obj = self.permission_class(thread_manager_obj,loop_index)\n        self.thread_manager_obj = thread_manager_obj\n        self.loop_index = loop_index\n        self.db_manager_client = self.db_manager_class(thread_manager_obj,loop_index)\n        #self.permission_mape\n\n    async def list(self, request):\n\n        if await self.permission_obj.has_permission(request.user, self.model_name,\'read\'):\n            data = await self.db_manager_client.list(request)\n            return data,200\n        else:\n            return "Invalid Authorization",400\n\n\n    async def create(self,request):\n        user = request.user\n\n        if await self.permission_obj.has_permission(user, self.model_name,\'write\'):\n            id = self.id_generetor(user)\n            data = request.data\n            data[self.pk] = id\n            serializer_data = self.serializer_class(data=data)\n            if serializer_data.is_valid():\n\n                self.permission_obj.assing_permission(user,self.model,id,\'*\',\'*\',True)\n                rs = await self.db_manager_client.create(request[\'data\'])\n                return (request.data, 201)\n            else:\n                return  (request.data, 406)\n\n        else:\n            return "Invalid Authorization",400\n\n\n    async def retrive(request, pk=None):\n        if self.permission_obj.has_permission(request.user, self.model_name,\'read\'):\n            if pk is not None:\n                if self.permission_obj.has_object_permission(request.user, pk,\'read\'):\n                    data = await self.db_manager_client.retrive(request,pk)\n                    return data,201\n                else:\n                    return \'Invalid Authorization for the item\',400\n        else:\n            return "Invalid Authorization",400\n\n    async def update(self,request, pk=None):\n        if self.permission_obj.has_permission(request.user, self.model_name,\'edit\'):\n            if pk is None:\n                return  (request.data, 400)\n            else:\n                if self.permission_obj.has_object_permission(request.user, pk,\'edit\'):\n                    data = request.data\n                    serializer_data = self.serializer_class(data=data)\n                    if serializer_data.is_valid():\n                        rs = await self.db_manager_client.update(request,pk)\n                        return (rs, 201)\n                else:\n                    return "Invalid Authorization for the item",400\n                else:\n                    return (rs, 406)\n\n        else:\n            return "Invalid Authorization",400\n\n    async def partial_update(self,request, pk=None):\n        return await self.update(request,pk)\n\n    async def destroy(request, pk=None):\n        if self.permission_obj.has_permission(request.user, self.model_name,\'delete\'):\n            if self.permission_obj.has_object_permission(request.user, pk,\'delete\'):\n                if pk is None:\n                    return  (request.data, 400)\n                else:\n                    rs = self.db_manager_client.destroy(request,pk)\n                    res1 = rs[\'row_effected\']\n                    if res1 > 0:\n                        return (request.data, 201)\n                    else:\n                        return (request.data, 406)\n\n            else:\n                return "Invalid Authorization for the item",400\n\n        else:\n            return "Invalid Authorization",400\n\n   # def create_router():\n   #     r = router()\n   #     temp_url = []\n   #     for x in self.function_dict:\n   #         temp_url.append(self.function_dict[x][0],self.function_dict[x][1],getattr(self,x))\n   #     r.urls = temp_url\n   #     return r\n', 'created_at': '2020-11-09 12:15:58.546165', 'time_stamp': 1604904358.5461833, 'import_parameters': '{"common_api_lib": ["router,GenClass", "custom"], "db_manager_client": ["DBClient", "custom"], "permission_model.permission_checker": ["ParmissionChecker", "custom"], "datetime": ["sys"], "serializers": ["Serializer", "custom"]}'}
#################################################################################
............................************************............................
{'namespace': 'network_models.buffer_call_process_1', 'created_by': 'sys', 'source_code': 'async def buffer_call_func(obj,session_obj,metadata):\n    #async with session_ob:\n    if metadata["status"] == "DONE":\n          return\n    if method in ["post", "put", "patch"]:\n        if metadata["request_format"] == "json":\n            if metadata["functionality_type"] != "socket":\n                data = json.dumps(metadata["request_parameter"])\n                if len(data) > metadata["buffer_size"]:\n                    for x in range(len(metadata)/metadata["buffer_size"]):\n                        v = await self.request_obj(session_ob, method)(metadata["request_url"], data = data[x*metadata["buffer_size"]:(x+1)*metadata["buffer_size"]])\n                else:\n                    v = await self.request_obj(session_ob, method)(metadata["request_url"], data = data[x*metadata["buffer_size"]:(x+1)*metadata["buffer_size"]])\n            else:\n                if len(data) <= metadata["buffer_size"]:\n                    async with request_obj(session_ob, method)(metadata["request_url"],max_msg_size = metadata["buffer_size"]) as ws:\n                        await ws.send_str(data)\n                        await ws.send_str("in_close")\n                        await ws.close()\n                else:\n                    async with request_obj(session_ob, method)(metadata["request_url"],max_msg_size = metadata["buffer_size"]) as ws:\n                        for x in range(len(data)/metadata["buffer_size"]):\n                            await ws.send_str(data)\n                        await ws.send_str("in_close")\n                        async for msg in ws:\n                            if msg.type == aiohttp.WSMsgType.ERROR:\n                                break\n                            if msg.type == aiohttp.WSMsgType.TEXT:\n                                if msg.data == \'out_close\':\n                                    await ws.close()\n                                    break\n                            v = msg.data ###return_parameter needed\n\n                            if metadata["return_function"] is not None:\n                                if metadata["return_parameter"] is not None:\n                                    yield metadata["return_function"](v,**metadata["return_parameter"])\n                                else:\n                                    yield metadata["return_function"](v)\n                            else:\n                                yield v  \n        else:\n            if metadata["functionality_type"] != "socket":\n                if len(metadata["request_parameter"])< metadata["buffer_size"]:\n                    v = await self.request_obj(session_ob, method)(metadata["request_url"], data = metadata["request_parameter"])\n                else:\n                    for x in range(len(metadata["request_parameter"])/metadata["buffer_size"]):\n                        v = await self.request_obj(session_ob, method)(metadata["request_url"], data = metadata["request_parameter"][x*metadata["buffer_size"]:(x+1)*metadata["buffer_size"]])\n            else:\n                data = (metadata["request_parameter"]).encode()\n                    if len(data) < metadata["buffer_size"]:\n                        async with request_obj(session_ob, method)(metadata["request_url"],max_msg_size = metadata["buffer_size"]) as ws:\n                            await ws.send_str(data)\n                            await ws.send_str("in_close")\n                            async for msg in ws:\n                                if msg.type == aiohttp.WSMsgType.ERROR:\n                                    break\n                                if msg.type == aiohttp.WSMsgType.TEXT:\n                                    if msg.data == \'out_close\':\n                                        await ws.close()\n                                        break\n                                v = msg.data ###return_parameter needed\n                    else:\n                        async with request_obj(session_ob, method)(metadata["request_url"],max_msg_size = metadata["buffer_size"]) as ws:\n                            for x in range(len(data)/metadata["buffer_size"]):\n                                await ws.send_str(data[x*metadata["buffer_size"]:(x+1)*metadata["buffer_size"]])\n                            await ws.send_str("in_close")\n                            async for msg in ws:\n                                if msg.type == aiohttp.WSMsgType.ERROR:\n                                    break\n                                if msg.type == aiohttp.WSMsgType.TEXT:\n                                    if msg.data == \'out_close\':\n                                        await ws.close()\n                                        break\n                                v = msg.data\n                                \n                if metadata["return_function"] is not None:\n                    if metadata["return_parameter"] is not None:\n                        yield metadata["return_function"](v,**metadata["return_parameter"])\n                    else:\n                        yield metadata["return_function"](v)\n                else:\n                    yield v\n        \n    else:\n        if metadata[\'functionality_type\'] !="socket":\n            async with self.request_obj(session_ob, method)(metadata["request_url"], params = metadata["request_parameter"]) as resp:\n                if metadata["return_function"] is None:\n                    while True:\n                        data = await self.request_method(resp, metadata["request_format"])(metadata["buffer_size"])\n                        if not data:\n                            break\n                        yield data\n                \n                else:\n                    while True:\n                        data = await self.request_method(resp, metadata["request_type"])(metadata["buffer_size"])\n                        if not data:\n                            break\n                        yield metadata["return_function"](data,**metadata["return_parameter"])\n\n        else:\n            async with session.ws_connect(metadata["request_url"],max_msg_size = metadata["buffer_size"])  as ws:\n                async for msg in ws:\n                    if msg.type == aiohttp.WSMsgType.ERROR:\n                        break\n\n                    if msg.type == aiohttp.WSMsgType.TEXT:\n                        if msg.data == \'close\':\n                            await ws.close()\n                            break\n                    elif metadata["return_function"] is None :\n                        yield msg.data\n                    else:\n                        yield metadata["return_function"](msg.data)\n\n    metadata["status"] = "DONE"\n    \n', 'created_at': '2020-11-09 12:15:58.564814', 'time_stamp': 1604904358.5648613, 'import_parameters': '{}'}
#################################################################################
............................************************............................
{'namespace': 'root_models.root_to_supperviser_communication', 'created_by': 'sys', 'source_code': 'MAXIMUM_COROUTING = 300000\n\n############################ corouting work ###################################################################\n\nclass RootToSupervisorCommunication:\n\n    async def start_assing_task_to_container(self,loop_index,ip_address,task):\n        #get_task_from_monitor. it should return port id of the service #####\n        print(self.loop_index,NETWORK_INTERFACE[\'OUT_NET\'],\'socket\',"json","http://"+ip_address+":10/get_task_from_monitor",task)\n        return await self.socket_object.send_single_request(self.loop_index,NETWORK_INTERFACE[\'OUT_NET\'],\'socket\',"json","http://"+ip_address+":10/get_task_from_monitor",task) \n\n    async def get_current_microservice_information(self,loop_index,ip_address):\n        \n        return await self.socket_object.send_single_request(self.loop_index,NETWORK_INTERFACE[\'OUT_NET\'],\'socket\',"json","http://"+ip_address+"/current_microservice_info",\'\') \n\n\n    async def start_reset_container(self,loop_index,ip_address):\n        #reset\n        return await self.socket_object.send_single_request(self.loop_index,NETWORK_INTERFACE[\'OUT_NET\'],\'socket\',"json","http://"+ip_address+"/reset",\'\')\n\n    async def start_restart_all_microservices_of_the_container(self,loop_index,ip_address):\n        #restart_all_microservices\n        return await self.socket_object.send_single_request(self.loop_index,NETWORK_INTERFACE[\'OUT_NET\'],\'socket\',"json","http://"+ip_address+"/restart_all_microservices",\'\')\n\n    async def start_shutdown_container_suppervisor(self,loop_index,ip_address):\n        #shutdown\n        return await self.socket_object.send_single_request(self.loop_index,NETWORK_INTERFACE[\'OUT_NET\'],\'socket\',"json","http://"+ip_address+"/shutdown",\'\')\n\n    async def start_shutdown_conatiner(self,loop_index,ip_address):\n        #shutdown_container\n        return await self.socket_object.send_single_request(self.loop_index,NETWORK_INTERFACE[\'OUT_NET\'],\'socket\',"json","http://"+ip_address+"/shutdown_container",\'\')\n\n    async def start_restart_microservice_of_container(self,loop_index,ip_address,namespace):\n        #restart_microservice\n        data = {\'namespace\':namespace}\n        return await self.socket_object.send_single_request(self.loop_index,NETWORK_INTERFACE[\'OUT_NET\'],\'socket\',"json","http://"+ip_address+"/restart_microservice",ujson.dumps(data))\n\n    async def start_delete_microservice_from_container(self,loop_index,ip_address,namespace):\n        data={\'namespace\':namespace}\n        return await self.socket_object.send_single_request(self.loop_index,NETWORK_INTERFACE[\'OUT_NET\'],\'socket\',"json","http://"+ip_address+"/delete_microservice",ujson.dumps(data))\n\n    async def start_delete_microservice_function_from_container(self,loop_index,ip_address,namespace,func_url):\n            #delete_microservice_function\n        data = {\'namespace\':namespace,\'url\':func_url}\n        urls = nginx_conf.search_url_for_ip_address(ip_address) ### [url1,url2,....]\n        if urls[0] == \'/\'+namespace +\'/\'+func_url:\n                return await self.start_shutdown_conatiner(self.loop_index,ip_address)\n        else:\n            return await self.socket_object.send_single_request(loop_index,NETWORK_INTERFACE[\'OUT_NET\'],\'socket\',"json","http://"+ip_address+"/delete_microservice_function",ujson.dumps(data))\n\n    async def start_debugging_to_container_microservices(self,loop_index,ip_address):\n            #start_debugging_all_microservices\n        return await self.socket_object.send_single_request(self.loop_index,NETWORK_INTERFACE[\'OUT_NET\'],\'socket\',"json","http://"+ip_address+"/start_debugging_all_microservices",\'\')\n\n    async def stop_debugging_to_container_microservices(self,loop_index,ip_address):\n        return await self.socket_object.send_single_request(self.loop_index,NETWORK_INTERFACE[\'OUT_NET\'],\'socket\',"json","http://"+ip_address+"/stop_debugging_all_micrservices",\'\')\n\n    async def start_debugging_to_container_microservice(self,loop_index,ip_address,namespace):\n            #start_function_debugging\n        data = {\'namespace\':namespace}\n        return await self.socket_object.send_single_request(self.loop_index,NETWORK_INTERFACE[\'OUT_NET\'],\'socket\',"json","http://"+ip_address+"/start_debugging_to_the_microservice",ujson.dumps(data))\n\n    async def stop_debugging_to_container_microservice(self,loop_index,ip_address,namespace):\n        data = {\'namespace\':namespace}\n        return await self.socket_object.send_single_request(self.loop_index,NETWORK_INTERFACE[\'OUT_NET\'],\'socket\',"json","http://"+ip_address+"/stop_debugging_to_the_micrservice",ujson.dumps(data))\n\n    async def get_container_ip_by_type_and_namespace(self,container_type,namespace):\n\n        container_info = ContainerObject.objects().filter(container_type = container_type).allow_filtering()\n\n        so = self.socket_object.get_session_obj(self.loop_index,NETWORK_INTERFACE[\'OUT_NET\'])#self.db_interface_list[\'REDIS\'])\n        temp_container_ip = None\n        temp_container_name =None\n\n\n        for x in container_info:\n            r = self.socket_object.register_request(\'socket\',"json","http://"+x.ip_address+"/report_all_service",\'\')\n            d = await self.socket_obj.run_request(so,r)\n            d = ujson.loads(d)\n            if d[\'namespace\'] == namespace:\n                yield x.ip_address\n        self.socket_object.release_session_obj(self.loop_index,NETWORK_INTERFACE[\'OUT_NET\'],so)\n\n    async def short_conatiner_by_no_of_running_corouting(self,loop_index,container_type):\n            #report_total_no_of_corouting\n        container_info = ContainerObject.objects().filter(container_type = container_type).allow_filtering()\n        container_net_info = ContainerObjectNetworking.objects().filter(container_type = container_type,inter_face_code =\'MONITOR_NET\').allow_filtering()\n\n        so = self.socket_object.get_session_obj(self.loop_index,NETWORK_INTERFACE[\'OUT_NET\'])#self.db_interface_list[\'REDIS\'])\n      \n        temp_container_ip = None\n        temp_no_corouting = MAXIMUM_COROUTING\n        temp_container_name =None\n\n\n        for x,y in zip(container_info,container_net_info):\n            r = self.socket_object.register_request(\'socket\',"json","http://"+y.ip_address+"/report_total_no_of_corouting",\'\')\n            d = await self.socket_object.run_request(so,r)\n            d = ujson.loads(d)\n            if d[\'no_of_co_routing\'] < temp_no_corouting:\n                temp_no_corouting = d[\'no_of_co_routing\']\n                temp_container_ip = y.ip_address\n                temp_container_name = x.container_name\n        self.socket_object.release_session_obj(self.loop_index,NETWORK_INTERFACE[\'OUT_NET\'],so)\n\n        return temp_container_ip, temp_container_name,temp_no_corouting\n', 'created_at': '2020-11-09 12:15:58.631138', 'time_stamp': 1604904358.63116, 'import_parameters': '{"meta_model.container_db": ["ContainerObject,ContainerObjectNetworking", "custom"], "config": ["NETWORK_INTERFACE", "custom"]}'}
#################################################################################
............................************************............................
{'namespace': 'thread_models.one_only_thread', 'created_by': 'sys', 'source_code': 'class thread_manager:\n    """Assigns coroutines to threads running in a container based on the number of coroutines present under the available threads"""\n\n    thread_lock = threading.Lock() ### lock for handeling thread\n    corouting_lock = threading.Lock() ## lock for handeling corouting\n    loop_lock = {}\n    loop_status = []\n    \n    \n    thread_list = []\n    thread_inactive_list = []\n    thread_pending_task = [] ## [{service_type:[UI|backup],[url:]}]\n    thread_info = {} ## {\'thread_id\':[{service_type:[UI|backup],[url:],\'status\':\'\'}}\n    task_meta = {\'backup\':\'call_corouting\',\'UI\':\'call_micro_service\',\'kafka\':\'call_kafaka_backend_process\',\'data_base\':\'call_db_handeler\'} ## this will be store meta information for the task \n    socket_class = SocketManagerClass\n    socket_object = None\n    loop_list = []\n    #loop_status = []\n    services = {} ####{"microservice":[]}\n\n    restart_loop =[]\n    \n    MINIMUM_LIMIT = 1\n    MAXIMUM_LIMIT = 3\n    REDUCE_FLAG = []#False\n    \n    INIT_PORT =10 \n    current_port = 0\n    in_net = None\n    #microservice_list=[]\n        \n    def next_port(self):\n        """Generates port for assigning new microservice"""\n        \n        if self.current_port == 0:\n            self.current_port = self.INIT_PORT\n            \n        else:\n            self.current_port += 1\n        \n        return self.current_port\n\n   \n    def __init__(self, corouting_class = coroutine_manager):\n        """Initiates new thread"""\n        \n        self.corouting_manager_obj = corouting_class(self)\n        self.socket_object = self.socket_class(self)\n        self.corouting_manager_obj.register_loop(0)\n        self.socket_object.register_loop(0)\n\n    def register_thread(self):\n        """Creates new thread and appends to thread list"""\n        t = threading.current_thread()\n        self.thread_list.append(t)\n        self.thread_info[0] = {\'status\':\'created\'}\n\n        self.REDUCE_FLAG.append(False) \n        l = asyncio.get_event_loop()\n        loop_id = len(self.loop_list)\n        self.loop_index = 0\n        self.loop_list.append(l)\n        self.loop_status.append(\'stop\')\n        asyncio.set_event_loop(loop = l)\n        self.loop_lock[0] = asyncio.Lock(loop=l)\n        self.call_corouting(self.loop_index)\n\n\n\n    async def call_micro_service(self,loop_index,task):\n        m = None\n        if \'microservices\' in self.services:\n            for x in self.services[\'microservices\']:\n                if x.status == \'Done\':\n                    m = x\n                    break\n            if m is None:\n                m = MicroService(self.next_port(),loop_index,self)\n                self.services[\'microservices\'].append(m)\n            else:\n                m.loop_index = loop_index\n        else:\n            m = MicroService(self.next_port(),loop_index,self)\n            self.services[\'microservices\']=[m]\n        \n        task[\'host\'] =self.in_net\n\n        \n        try:\n            \n\n            await m.microservice(class_name = task[\'class_name\'],name_space = task[\'name_space\'],host = task[\'host\'],urls= task[\'urls\'])\n        except:\n            \n\n            await m.microservice(class_name = task[\'class_name\'],name_space = task[\'name_space\'],host = task[\'host\'])\n\n        return m.port\n\n            \n\t\t\t\t\n\n\n    def call_corouting(self,loop_index):\n        try:\n            self.corouting_manager_obj.num_of_corouting_in_loop[loop_index]\n        except:\n\n            self.corouting_manager_obj.register_loop(loop_index)\n        try:\n            self.services[\'backup\']\n        except:\n            self.services[\'backup\'] = self.corouting_manager_obj\n\n        self.corouting_manager_obj.start_loop_coroutings(loop_index)\n\n    def assign_loop(self):\n        \n        l = self.loop_list[0]\n        while True:\n           \n            if l.is_closed():\n                l = asyncio.new_event_loop()\n                self.loop_list[loop_id] = l\n                asyncio.set_event_loop(loop = l)\n                self.loop_lock[thread_id] = asyncio.Lock(loop=l)\n\n            if self.REDUCE_FLAG[0]:\n                return\n            else:\n                self.loop_status[0] = \'running\'\n                l.run_forever()\n               \n\n    def reduce_thread(self,thread_id):\n        self.REDUCE_FLAG[thread_id] = True\n\t\n\n', 'created_at': '2020-11-09 12:15:58.642024', 'time_stamp': 1604904358.6420422, 'import_parameters': '{"threading": ["sys"], "asyncio": ["sys"], "network_models.socket_manager": ["SocketManagerClass", "custom"], "thread_models.coroutine_manager_only_one_thread": ["coroutine_manager", "custom"], "thread_models.support_only_one_thread": ["MicroService", "custom"]}'}
#################################################################################
............................************************............................
{'namespace': 'suport_thread.import_model', 'created_by': 'sys', 'source_code': '\nroot_path = \'import_folder\'\n\nclass ImportManager:\n    \n    name_space_list = {} ### {namespace:{filename:str,is_imported:bool[True:False]}\n    root_folder = root_path\n    addition_info = {} ### {namespace:{}} This will containg addition infomation except source code + namespace from the data base\n    \n    def __init__(self):\n        self.name_space_list[\'config\'] = {\'filename\':\'../config\'}\n        p = pathlib.Path(self.root_folder)\n        self.config = importlib.import_module(\'base_model.config\')\n        if not p.exists():\n            os.makedirs(self.root_folder)\n\n        #self.config = config\n\n    class Comm:\n        pass\n\n\n    def add_namespace(self,name_space):\n        """Namespace face and add to local data structure"""\n        #print(name_space)\n        data=None\n        temp_str =""\n        try:\n            self.name_space_list[name_space]\n        except:\n           \n            #temp_str = ""\n            print(name_space)\n            data = MicroserviceResource.objects().filter(namespace = name_space).allow_filtering().first()\n            if data is None:\n                print(\'haiiiiiiiiiii\',name_space)\n                return\n#MicroserviceResource.objects.get(namespace = name_space)\n            #print(data)\n            import_parameter = ujson.loads(data.import_parameters)#[\'model\']\n                        #print(type(import_parameter))\n            #print(import_parameter)\n            if import_parameter !={}:\n                #print(import_parameter)\n\n                for x in import_parameter:\n\n                    if \'sys\' not in import_parameter[x]:\n                #        continue\n                        try:\n                            self.name_space_list[x]\n                        except:\n                #            pass\n                           \n                            self.add_namespace(x)\n                        finally:\n                ###        pass\n                            temp_str+=\'from base_model.suport_thread.import_model import import_manager_obj\\n\'\n                            if len(import_parameter[x])>1:\n                                for y in import_parameter[x][0].split(\',\'):\n                                    temp_str +=y+" = import_manager_obj."+x+"."+y+"\\n"\n                            else:\n                                temp_str+=\'import \'+x+\'\\n\'\n                    else:\n                        #try:\n                    ##        #self.name_space_list[x]\n                    ##    #except:\n                        if len(import_parameter[x])>1:\n                            temp_str +="from "+x+" import "+import_parameter[x][0]+"\\n"\n                        else:\n                            temp_str+=\'import \'+x+\'\\n\'\n\n                    ##        #pass\n                    #    \n                    #    #    return False\n\n                    #    #self.add_namespace(x,import_parameter[x],\'system\')\n                        #temp_str +="from "+x+" import ("\n                        \n            #print(temp_str)\n            #   pass\n            #for y in import_parameter[x]["model"]:\n            #    temp_str +=y+" = import_manager_obj."+x+"."+y+"\\n"\n            source_code  = temp_str + data.source_code\n            self.addition_info[name_space] ={}\n            self.addition_info[name_space][\'source_url\'] = data.source_url\n            self.addition_info[name_space][\'sub_url\'] = data.sub_url\n            self.addition_info[name_space][\'created_by\'] = data.created_by\n            self.addition_info[name_space][\'created_at\'] = data.created_at\n            self.addition_info[name_space][\'time_stamp\'] = data.time_stamp\n            self.addition_info[name_space][\'import_parameters\'] = data.import_parameters \n            #print(source_code)\n            #\n            snp = name_space.split(\'.\')\n            file_name = ""\n            ch = self\n            if len(snp)>1:\n\n                #print(snp)\n                sdir = self.root_folder+\'/\'+\'/\'.join(snp[:len(snp)-1])\n                #print(sdir)\n                if not pathlib.Path(sdir).exists():\n                    \n                    os.makedirs(sdir)\n                tf = self.root_folder+\'.\'+name_space\n                #print(tf)\n\n                file_name = sdir+\'/\'+snp[len(snp)-1]+\'.py\'\n                #print(file_name)    \n                for x in range(len(snp)-1):\n                #   \n                    try:\n                        getattr(ch,snp[x])\n                #        \n                    except:\n                        temp = self.Comm()\n                #        print(snp[x])\n                        setattr(ch,snp[x],temp)\n                    ch = getattr(ch,snp[x])\n                #file_name = self.root_folder+\'/\'+file_name\n\n                self.name_space_list[name_space] = file_name\n                f = open(file_name,\'w+\')\n                f.write(source_code)\n                f.close()\n                #print(tf)\n                ##\n                ##print(name_space)\n                #m = input(\'haii try\')\n                time.sleep(1/(10**2))\n                temp = importlib.import_module(tf)\n                #m = input(\'haii try\')\n                setattr(ch,snp[-1],temp)\n\n            else:\n                tf = self.root_folder+\'.\'+name_space\n                file_name = name_space+\'.py\'\n                file_name = self.root_folder+\'/\'+file_name\n                self.name_space_list[name_space] = file_name\n#                print(file_name)\n                f = open(file_name,\'w+\')\n                f.write(source_code)\n                f.close()\n                #print(tf)\n\n                #temp = importlib.import_module(tf)\n                #setattr(ch,name_space,temp)\n\n        \n        finally:\n            pass\n            \n\n    def walk(self,path): \n        \'\'\' This is the walk function it tarvel from top of the path to end. path is the namespace like "a.b.c.d" it will return d object.\'\'\'\n        array_str = path.split(\'.\')\n        temp_obj = getattr(self,array_str[0])\n        array_str = array_str[1:]\n        for x in array_str:\n            temp_obj = getattr(temp_obj,x)\n\n        return temp_obj\n\n    def update_namespace(self,namespace):\n        del self.name_space_list[namespace]\n        self.add_namespace(namespace)\n       \n       \n    def delete_namespace(self,namespace):\n        snp = namespace.split(\'.\')\n        \n        ch  = self\n        #print(getattr(ch,snp[0]))\n\n        for x in range(len(snp)-1):\n            ch = getattr(ch,snp[x])\n        m = getattr(ch,snp[len(snp)-1])\n        del m\n\n       \n    def list(self):\n        return self.name_space_list\n   \n   \n###will be moved to common_api\n\n    def reset(self):\n        m = list(self.name_space_list.keys())\n        m.remove(\'config\')\n        for x in m:\n            self.update_namespace(x)\n\n        \n    def preprocess_source_code(self,namespace):\n        """This function get the actual source code and compile the code"""\n        try:\n            self.name_space_list[namespace]\n        except:\n            self.add_namespace(namespace)\n                 \n\n', 'created_at': '2020-11-09 12:15:58.647986', 'time_stamp': 1604904358.6480072, 'import_parameters': '{"sys": ["sys"], "importlib": ["custom"], "ujson": ["sys"], "uuid": ["sys"], "meta_model.container_db": ["MicroserviceResource", "custom"], "os": ["sys"], "pathlib": ["sys"], "time": ["sys"], "=": ["custom"]}'}
#################################################################################
............................************************............................
{'namespace': 'permission_model.db_models', 'created_by': 'sys', 'source_code': "db_json_list = [\n        {\n        'model_name':'PermissionItemDefaultPermission',\n        'table_info':{\n            'default_permission_code':{'type':'string','required':True},\n            'model':{'type':'string','required':True},\n            'index':['model']\n            },\n        'data_base_type':['Cassandra','Prosgresql'],\n        'data_server':'default',\n        'backup_db':['Postgresql'],\n        'operation':['*']\n        },\n\n        {\n            'model_name':'PermissionPermissionBitMapper',\n            'table_info':{\n                'permission_code':{'type':'string','required':True},\n                'bits_position':{'type':'int','required':False},\n                'created_at':{'type':'datetime','required':False},\n                'index':['permission_code']\n                },\n            'redis_type':'not_list',\n            'data_base_type':['*'],\n            'data_server':'default',\n            'backup_db':['Postgresql'],\n            'operation':['*']\n            },\n        {\n            'model_name':'PermissionPermissionCode',\n            'table_info':{\n                'permission':{'type':'string','required':True},\n                'permission_code':{'type':'string','required':False},\n                'created_at':{'type':'datetime','required':False},\n                'index':['permission']\n                },\n            'redis_type':'not_list',\n            'data_base_type':['*'],\n            'data_server':'default',\n            'backup_db':['*'],\n            'operation':['*']\n            },\n        {\n            'model_name':'PermissionGroupPermissionForItem',\n            'table_info':{\n                'permission_codes_string':{'type':'string','required':True},\n                'item_code':{'type':'string','required':True},\n                'timestamp':{'type':'float','required':False},\n                'is_special_permission':{'type':'boolean','default':'False'},\n                'special_permission':{'type':'string','required':False}, #### {'user01':'write+read+delete=7'}\n                'index':['item_code']\n                },\n            'redis_type':'not_list',\n            'data_base_type':['*'],\n            'data_server':'default',\n            'backup_db':['*'],\n            'operation':['*']\n            },\n        {\n            'model_name':'PermissionPermissionForModel',\n            'table_info':{\n                'permission_codes_string':{'type':'string','required':True},\n                'model_code':{'type':'string','required':True},\n                'created_at':{'type':'datetime','required':False},\n                'resource_url':{'type':'float','required':True},\n                'index':['model_code']\n                },\n            'redis_type':'model_list',\n            'data_base_type':['*'],\n            'data_server':'default',\n            'backup_db':['*'],\n            'operation':['*']\n            },\n        {\n            'model_name':'PermissionGroupBitsMapper',\n            'table_info':{\n                'bits_position':{'type':'int','required':False},\n                'group_code':{'type':'string','required':True},\n                'created_at':{'type':'datetime','required':False},\n                'index':['group_code']\n                },\n            'redis_type':'model_list',\n            'data_base_type':['*'],\n            'data_server':'default',\n            'backup_db':['*'],\n            'operation':['*']\n            },\n        {\n            'model_name':'PermissionGroup',\n            'table_info':{\n                'group_code':{'type':'string','required':False},\n                'created_at':{'type':'datetime','required':False},\n                'group':{'type':'string','required':True},\n                'index':['group']\n                },\n            'redis_type':'model_list',\n            'data_base_type':['*'],\n            'data_server':'default',\n            'backup_db':['*'],\n            'operation':['*']\n            },\n        {\n            'model_name':'PermissionUserGroup',\n            'table_info':{\n                'userid':{'type':'string','required':True},\n                'group_code':{'type':'string','required':False},\n                'index':['userid']\n                },\n            'redis_type':'model_list',\n            'data_base_type':['*'],\n            'data_server':'default',\n            'backup_db':['*'],\n            'operation':['*']\n            },\n        {\n            'model_name':'PermissionItemOwner',\n                'table_info':{\n                'user':{'type':'string','required':True},\n                'item':{'type':'string','required':True},\n                'time_stamp':{'type':'float','required':True},\n                'index':['item_id']\n                },\n                'redis_type':'not_list',\n                'data_base_type':['*'],\n                'data_server':'default',\n                'backup_db':['Postgresql'],\n                'operation':['*']\n        },\n        {\n            'model_name':'PermissionItemOwner',\n                'table_info':{\n                'userid':{'type':'string','required':True},\n                'item_id':{'type':'string','required':False},\n                'index':['item_id']\n                },\n                'redis_type':'not_list',\n                'data_base_type':['*'],\n                'data_server':'default',\n                'backup_db':['Postgresql'],\n                'operation':['*']\n        }\n\n\n]\n", 'created_at': '2020-11-09 12:15:58.655048', 'time_stamp': 1604904358.6550703, 'import_parameters': '{}'}
#################################################################################
............................************************............................
{'namespace': 'authentication_model.final', 'created_by': 'sys', 'source_code': '### Stp flows user done digital signatur------> generate and assing the authenticat token ---> generate and assing the session token -----> in logout time remove the token -----> login time reganaret regenerate the token ------> reset RSA key on reset device or password\n\ntoken_table = \n\n        {\n            \'model_name\':\'UserAuthenticationToken\',\n            \'table_info\':{\n                \'token\':{\'type\':\'string\',\'required\':True},\n                \'user\':{\'type\':\'string\',\'required\':True},\n                \'login_time\':{\'type\':\'float\',\'required\':True},\n                \'aes_key\':{\'type\':\'string\',\'required\':True},\n\n                \'index\':[\'token\']\n                },\n            \'redis_type\':\'not_list\',\n            \'data_base_type\':[\'*\'],\n            \'data_server\':\'default\',\n            \'backup_db\':[\'Postgresql\'],\n            \'operation\':[\'*\']\n            }\n\n\n\nclass CommonEncriptionOperation:\n    keysize = 32\n    def assing_session_token(self):\n        token = secrets.token_urlsafe(self.keysize)#secrets.token_bytes(self.keysize)\n\n        return token\n\n    def assing_aes_key(self):\n        return secrets.token_urlsafe(self.keysize)#secrets.token_bytes(self.keysize)\n\n\nclass AuthenticatUser(CommonEncriptionOperation):\n    rsa_key_size = 2048\n    aes_key_size = 1024\n    hash = "SHA-256"\n    table_client =SecurityDataBaseClient\n    table_client_obj = None\n    token_size = 32\n\n\n\n    def __init__(self,thread_obj,loop_index):\n        self.table_client_obj = self.table_client()\n\n    def rsa_newkeys(self):\n\n        random_generator = Random.new().read\n        key = RSA.generate(self.rsa_key_size, random_generator)\n        return key, key.publickey()\n        #return public, private\n\n    def exportkey(self,key):\n        \'\'\'Key to string converter\'\'\'\n\n        binkey =  key.exportKey(\'DER\')\n        return binkey\n\n    def importKey(self,externKey):\n        \'\'\'String to key converter\'\'\'\n\n        return RSA.importKey(externKey)\n\n    def encrypt(self,message, pub_key):\n        #RSA encryption protocol according to PKCS#1 OAEP\n        cipher = PKCS1_OAEP.new(pub_key)\n        return cipher.encrypt(message)\n\n    def decrypt(self,ciphertext, priv_key):\n        #RSA encryption protocol according to PKCS#1 OAEP\n        cipher = PKCS1_OAEP.new(priv_key)\n        return cipher.decrypt(ciphertext)\n\n    def sign(self,message, priv_key, hashAlg="SHA-256"):\n        \'\'\' Sign on the massage\'\'\'\n        global hash\n        hash = hashAlg\n        signer = PKCS1_v1_5.new(priv_key)\n        if (hash == "SHA-512"):\n            digest = SHA512.new()\n        elif (hash == "SHA-384"):\n            digest = SHA384.new()\n        elif (hash == "SHA-256"):\n            digest = SHA256.new()\n        elif (hash == "SHA-1"):\n            digest = SHA.new()\n        else:\n            digest = MD5.new()\n        digest.update(message)\n        return signer.sign(digest)\n\n    ############# User Authentication steps (web services list)  #######################\n\n\n    async def start_user_registation(self,request):\n        \'\'\' assing public key and token information to the user.\'\'\'\n        token = self.assing_session_token()\n        sys_public_key,sys_private_key = self.rsa_newkeys()\n        data = {\'sys_private_key\':self.exportkey(sys_private_key),\'session_token\':token}\n        self.table_client_obj.create(data)\n        data = {\'sys_public_key\':self.exportkey(sys_public_key),\'session_token\':token}\n        return data\n\n    async def recive_user_public_key(self,request):\n        #data = request.data\n        enrypted_data = request.data\n        token = request\n        sys_private_key = self.table_client_obj.retrive(token)[\'sys_private_key\'] ### store private_key\n        data = ujson.loads(self.decrypt(encrypted_data,private_key))\n        user_public_key = data[\'public_key\']\n        data = {\'sys_private_key\':self.exportkey(sys_private_key),\'session_token\':token,\'user_public_key\':user_public_key}\n        self.table_client_obj.create(data)\n\n    async def verify(self,request):\n        \'\'\'verify the user\'\'\'\n        token = request\n        sys_data = self.table_client_obj.retrive(token)\n        sys_private_key = sys_data[\'sys_private_key\']\n        user_public_key = sys_data[\'user_public_key\']\n\n        encrypted_data = request.data\n        data  = ujson.loads(self.decrypt(encrypted_data,private_key))\n        message = data[\'message\']\n        signature = data[\'signature\']\n        signer = PKCS1_v1_5.new(user_public_key)\n        if (hash == "SHA-512"):\n            digest = SHA512.new()\n        elif (hash == "SHA-384"):\n            digest = SHA384.new()\n        elif (hash == "SHA-256"):\n            digest = SHA256.new()\n        elif (hash == "SHA-1"):\n            digest = SHA.new()\n        else:\n            digest = MD5.new()\n        digest.update(message)\n        if signer.verify(digest, signature):\n            aes_key = self.assing_aes_key()\n            sys_data[\'aes_key\'] = aes_key\n            self.table_client_obj.create(data)\n            return \'Done\',200\n        else:\n            return \'Signature does not match\',400\n\n\n\nclass CommunicationPipe(CommonEncriptionOperation):\n    payload = "b"*16\n    rsa_key_size = 2048\n    aes_key_size = 1024\n    hash = "SHA-256"\n    table_client =SecurityDataBaseClient\n    table_client_obj = None\n    token_size = 32\n    def __init__(self,thread_obj,loop_index):\n        self.table_client_obj = self.table_client()\n\n    def aes_encrypt(self,payload, salt, key):\n        return AES.new(key, AES.MODE_CBC, salt).encrypt(r_pad(payload))\n\n\n    def aes_decrypt(self,payload, salt, key, length):\n        return AES.new(key, AES.MODE_CBC, salt).decrypt(payload)[:length]\n\n\n    def r_pad(self,payload, block_size=16):\n        length = block_size - (len(payload) % block_size)\n        return payload + chr(length) * length\n\n\n\n    async def send_data(self,data,aes_key)#,aes_key):\n        data[\'next_key\'] = secrets.token_hex(self.token_size)\n        aes_key = self.table_client_obj.retrive({\'user_token\':user_token})\n        return aes_encrypt(data,self.payload,aes_key)\n\n    async def recive_data(self,request): ### level = 0 or Non,1 or User authorization ,2 or model authorization,3 or request authorization\n        encrypted_data =request.data#,aes_key\n        user_token = None\n        if "Authorization" in req.headers:\n            user_token = request.headers["Authorization"]\n        else:\n            return False,\'Authrentication required\',400\n        sys_data = self.table_client_obj.retrive({\'user_token\':user_token})\n        if sys_data ==[]:\n            return \'Invalid user or user need to login\',400\n\n\n        data = aes_decrypt(encrypted_data,self.payload,sys_data[\'aes_key\'])\n\n        return True, data, sys_data[\'user\'], sys_data[\'aes_key\']\n', 'created_at': '2020-11-09 12:15:58.672744', 'time_stamp': 1604904358.672771, 'import_parameters': '{"Crypto.PublicKey": ["RSA", "custom"], "Crypto.Cipher": ["AES", "custom"], "Crypto.Signature": ["PKCS1_v1_5", "custom"], "Crypto.Hash": ["SHA512,", "custom"], "Crypto": ["Random", "custom"], "base64": ["b64encode,", "custom"], "rsa": ["custom"], "secrets": ["custom"], "authentication_model": ["encrypcommunication", "custom"], "ujson": ["sys"], "authentication_model.secureity_dbclient": ["SecurityDataBaseClient", "custom"]}'}
#################################################################################
............................************************............................
{'namespace': 'back_end_processes.fanout_model.kafka_fun_namespace', 'created_by': 'sys', 'source_code': "class KafkaFuncClass:\n    service_func_list = []\n\n    def generate_sevice_fun(self):\n        class_name = type(self).__name__+'.{}'\n        func_list_dic = {}\n        for x in self.service_func_list:\n            func_list_dic[class_name.format(x)] = getattr(self,x)\n\n        return func_list_dic\n\n    def __init__(thread_obj):\n        self.thread_obj = thread_obj\n", 'created_at': '2020-11-09 12:15:58.690539', 'time_stamp': 1604904358.6905603, 'import_parameters': '{}'}
#################################################################################
............................************************............................
{'namespace': 'meta_model.container_db', 'created_by': 'sys', 'source_code': '#from base_model import config\n\n\n#### Container type to nginx mapper ###########\nContanerTypeToNginxMapping = {     \n    \'MANAGER\':{\'IN_NET\':\'14.0.0.2\',\'OUT_NET\':\'15.0.0.2\',\'url_type\':\'mn_con\'},\n    \'UI\':{\'IN_NET\':\'\',\'OUT_NET\':\'\',\'url_type\':\'ui_con\'}\n}\n\n\nclass KafkaMsgMeta(Model):\n    kafka_broker_cluster = columns.Text(primary_key=True, required = True) ## cluster name by str like DEFULT \n    fun_name_list = columns.Text(required = True) ## json array {namespace:{\'class_name\':[funtion_name]}}\n    kafka_broker_list = columns.Text() ## json array\n    name_space = columns.Text(partition_key=True,required=True) ### json array [name_space]\n    \n\n\nclass ServerInfo(Model):\n    container_name = columns.Text(required=True,primary_key=True)\n    containerip = columns.Text()\n    no_of_threads = columns.Integer()\n    master_port = columns.Text()\n\n#class ThreadInfo(Model):\n#    thread_url = columns.Text()\n#    container_name = columns.Text(required=True,partition_key=True)\n#    thread_port = columns.Text(required=True,partition_key = True)\n#\n#class ContainerUrlMapping(Model):\n#    container_name = columns.Text(required=True,partition_key = True)\n#    namespace = columns.Text(required=True,partition_key=True)\n\n\nclass UrlTypeProtocalMapping(Model): ## bridge information should be exist befor service has been created.\n    url_type = columns.Text(primary_key=True) ### ui\n    protocal = columns.Text()                 ### http\n\nclass UrlMethodMapping(Model): ### may not require\n    url_type = columns.Text()\n    method = columns.Text() ### not require\n    url = columns.Text(primary_key = True)\n\nclass ContainerIso(Model):\n    container_type = columns.Text(primary_key=True, max_length=255)\n    container_iso  = columns.Text(max_length=255)\n    container_dir = columns.Text()\n\nclass NetworkInterface(Model):\n    netmask = columns.Integer()\n    base_ip = columns.Text(max_length=255)\n    inter_face_type = columns.Text(max_length=255) ### UI_INNET, UI_OUTNET, MANAGER_INNET, MAN_OUT, MONITOR_NET,\n    inter_face_code = columns.Text(max_length=255, primary_key = True) # bridge name\n    inter_face_name = columns.Text(max_length=255)\n\n#class Naginx(Model):\n#    name = columns.Text() ### ui\n#    url_type = columns.Text()\n\nclass ContainerObject(Model):\n    container_name = columns.Text(primary_key= True)\n    container_type = columns.Text(max_length=255,partition_key=True)\n    status = columns.Text(max_length = 255) ####  running, not_running, stop\n\nclass ContainerObjectNetworking(Model):\n    ip_address = columns.Text(primary_key=True, max_length=50)\n    container_type = columns.Text(partition_key=True,max_length=255)\n    container_name = columns.Text(required= True,partition_key=True)\n    master_ip_address = columns.Text() ## X\n    inter_face_code = columns.Text(max_length=255) ### inter_face_type\n\nclass ContainerNetworking(Model):\n    container_type = columns.Text(max_length=255,partition_key=True)\n    inter_face_type = columns.Text(max_length=255,partition_key = True)\n\nclass MicroserviceResource(Model):\n    namespace = columns.Text(required=True,primary_key=True)\n    source_url = columns.Text()\n    sub_url = columns.Text() ###  [\'/create\',\'/update\',\'/delete\',\'/list\',\'/retrieve\']\n    source_code = columns.Text(required=True)\n    created_by = columns.Text(required=True)\n    created_at = columns.Text(required=False)\n    time_stamp = columns.Float(required=True)\n    import_parameters = columns.Text() ### import parameter list {"namespace":["model",.....]}###\n    microservice_class_name = columns.Text()\n    is_core = columns.Boolean(default=True,partition_key=True) \n    \n    #level = columns.Text() ### lvl_0 for system restart, lvl_1_1 for supervisor restart, lvl_1_2 for monitor restart, lvl_2 for supervisor microservice restart\n    container_type = columns.Text()\n    \n\nsetup([MICROSERVICE_API["MICROSERVICE_SOURCE"]["DATA_BASE_STRING"]["CASSANDRA"]["IP"]], MICROSERVICE_API["MICROSERVICE_SOURCE"]["DATA_BASE_STRING"]["CASSANDRA"]["KEY_SPACE"], retry_connect=True)\nsync_table(ContainerNetworking)\nsync_table(ContainerObject)\nsync_table(ContainerObjectNetworking)\nsync_table(NetworkInterface)\nsync_table(ContainerIso)\nsync_table(UrlTypeProtocalMapping)\nsync_table(UrlMethodMapping)\nsync_table(ServerInfo)\nsync_table(MicroserviceResource)\n', 'created_at': '2020-11-09 12:15:58.693995', 'time_stamp': 1604904358.6940212, 'import_parameters': '{"uuid": ["sys"], "cassandra.cqlengine": ["columns,connection", "sys"], "datetime": ["datetime", "sys"], "cassandra.cqlengine.management": ["sync_table", "sys"], "cassandra.cqlengine.models": ["Model", "sys"], "cassandra.cqlengine.connection": ["setup", "sys"], "config": ["MICROSERVICE_API", "custom"]}'}
#################################################################################
............................************************............................
{'namespace': 'service_models.data_base.database_viewsets.cassandra_model.cassandra_backend_supported_viewset', 'created_by': 'sys', 'source_code': '\nclass CassandraManagerForBackend(CassandraManager): #### for microservice support ####\n    need_backend = True\n    backend_class = None\n    #cluster_name = None\n    task_name = None\n    \n    def __init__(self,thread_obj,loop_index,task):\n        self.thread_obj = thread_obj\n        self.corouting_manager_obj = thread_obj.corouting_manager_obj\n        #if self.backend_class is None:\n        #    self.name = type(self).__name__+\'Backend\'\n        #else:\n        #    self.name = self.backend_class.__name__\n        obj = self.backend_class.__name__()\n        services = obj.get_services()\n        self.task_name = task[\'namespace\']\n\n        self.corouting_manager_obj.register_service(task[\'namespace\'],services)\n            \n    async def create(self,request):\n        task_meta = {\'service\':self.task_name,\'service_fun\':\'create\',\'data\':request.data}\n        self.thread_obj.corouting_manager_obj.add_pending_task_list(task_meta)\n        return \'OK\'\n\n    async def update(self,request): ### pk come from request\n        task_meta = {\'service\':self.task_name,\'service_fun\':\'update\',\'data\':request.data}\n        self.thread_obj.corouting_manager_obj.add_pending_task_list(task_meta)\n        return \'OK\'\n\n    async def partial_update(self,request): ### pk come from reques\n        task_meta = {\'service\':self.task_name,\'service_fun\':\'update\',\'data\':request.data}\n        self.thread_obj.corouting_manager_obj.add_pending_task_list(task_meta)\n        return \'OK\'\n        #data[self.pk] = pk\n        #return self.keyspace.save(data)\n\n    async def destroy(self,request): ### pk come from request obj\n        task_meta = {\'service\':self.task_name,\'service_fun\':\'destroy\',\'data\':request.data}\n        self.thread_obj.corouting_manager_obj.add_pending_task_list(task_meta)\n        return \'OK\'\n        \n\n    \n\n#cassandra_manager_obj = CassandraManager()\n\nclass CassandraManagerBackend(BackendProcess): #### for backend support\n    #network_interface = ""\n    lookup_field = "user"\n    table = None\n    cluster_name = None\n    order_field = None\n    pk = \'id\'\n    separator = \',\'\n    fun_list = [\'create\',\'update\',\'destroy\',\'partial_update\']\n    allow_fun = [\'*\']\n    \n    #def __init__(self,thread_obj):\n    #    self.thread_obj = thread_obj\n            \n    \n    async def create(self,loop_index,metadata):\n        data = metadata[\'data\']\n        obj = self.table(**data)\n        return obj.using(connection=self.cluster_name).save()\n\n    async def update(self,loop_index,metadata): ### pk come from request\n        data =  metadata[\'data\']\n        obj = self.table(**data)\n        return self.obj.using(connection=self.cluster_name).save()\n\n    async def partial_update(self,loop_index,metadata): ### pk come from request\n        data = metadata[\'data\']\n        #data[self.pk] = pk\n        obj = self.table(**data)\n        return obj.using(connection=self.cluster_name).save()\n\n    async def destroy(self,loop_index,metadata): ### pk come from request obj\n        data = metadata[\'data\']\n        #print(data)\n        pk = data[self.pk]\n        self.table.objects(**{self.pk:pk}).using(connection=self.cluster_name).delete()\n        \n        return \n\n', 'created_at': '2020-11-09 12:15:58.785610', 'time_stamp': 1604904358.785637, 'import_parameters': '{"service_models.data_base.database_viewsets.cassandra_model.cassandra_viewset": ["CassandraManager", "custom"], "common_models.common_api_lib": ["BackendProcess", "custom"]}'}
#################################################################################
